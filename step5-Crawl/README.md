# 💬Python3 网络爬虫 
&emsp;&emsp;"得数据者得天下"。在大数据盛行的今天，你或许很容易能在网上看到什么"年度总结"，这些东西就是一系列的数据。网上还有很流行的词云，也是通过爬虫爬取下来的数据整理的。总之，会爬虫者得数据，得数据者得天下。

---

#### *📑快捷目录：*
[1. 开发环境配置](#1)

[2. 爬虫基础](#2)

[3. 基本库的使用](#3)

[4. 解析库的使用](#4)

[5. 数据存储](#5)

[6. Ajax 数据爬取](#6)

[7. 动态渲染页面爬取](#7)

[8. 验证码的识别](#8)

[9. 代理的使用](#9)

[10. 模拟登录](#10)

[11. App 的爬取](#11)

[12. pyspider 框架的使用](#12)

[13. Scrapy 框架的使用](#13)

[14. 分布式爬虫](#14)

[15. 分布式爬虫的部署](#15)

---

<a name="1"></a>
## 1. 开发环境配置
&emsp;&emsp;🐍安装库的方法有很多种，但我们选用最简单的第三方包管理工具[pip](#no-jump)来安装。使用的方法很简单，只需要打开命令行，输入`pip install ***`

1.1. [请求库的安装](#1.1)<br>
1.2. [解析库的安装](#1.2)<br>
1.3. [数据库的安装](#1.3)<br>
1.4. [存储库的安装](#1.4)

---

<a name="1.1"></a>
<div align="center">
  <strong><a href="#1.1">1.1</a> 请求库的安装</strong>
</div>
  
  ---
  
  - ***requests 的安装***
    ```python
    pip install requests
    ```
    
    ---
    
  - ***Selenium 的安装***
    ```python
    pip install selenium
    ```
    
    ---
    
  - ***ChromeDriver 的安装***
    

---

[返回目录⬆](#快捷目录)

<a name="2"></a>
## 2. 爬虫基础
